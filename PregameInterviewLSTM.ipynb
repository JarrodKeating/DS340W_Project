{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "df = pd.read_csv(\"/DS340W_Project/Sentiment_Scores.csv\")\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Masking\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Activation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "sep = \" \"\n",
    "for (i, text) in enumerate(df.Text):\n",
    "    splitted = text.split()\n",
    "    stemmed = [ps.stem(word) for word in splitted]\n",
    "    df.Text[i] = sep.join(stemmed)\n",
    "\n",
    "text = df['Text']\n",
    "labels = array(df['Rating'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(text, labels , test_size = 0.20)\n",
    "\n",
    "vocab_size = 500\n",
    "\n",
    "print(X_train[1])\n",
    "X_train = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True, split=' ') for d in X_train]\n",
    "X_test = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True, split=' ') for d in X_test]\n",
    "print(X_train[1])\n",
    "\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "y_test = to_categorical(np.array(y_test))\n",
    "\n",
    "\n",
    "\n",
    "x_train_lens = [len(x) for x in X_train]\n",
    "x_test_lens = [len(x) for x in X_test]\n",
    "max_len = max(max(x_train_lens), max(x_test_lens))\n",
    "\n",
    "# truncate and pad input sequences\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create the model. hyper-paramter tuning\n",
    "trials = 3\n",
    "nodes = [5, 15, 25, 35, 45]\n",
    "b_size = [8, 16, 32, 64]\n",
    "resultsMean = []\n",
    "resultsStd = []\n",
    "\n",
    "for n in nodes:\n",
    "  curResultMean = []\n",
    "  curResultStd = []\n",
    "  for b in b_size:\n",
    "    curDataAll = []\n",
    "    for t in range(trials):\n",
    "      embedding_vector_length = b\n",
    "      model = Sequential()\n",
    "      model.add(Embedding(vocab_size, embedding_vector_length, input_length=max_len))\n",
    "      model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "      model.add(Bidirectional(LSTM(n)))\n",
    "      model.add(Dense(4, activation='softmax'))\n",
    "      model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "      print(model.summary())\n",
    "      model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=16)\n",
    "      curDataAll.append(model.evaluate(X_test, y_test)[1])\n",
    "    curResultMean.append(np.mean(curDataAll))\n",
    "    curResultStd.append(np.std(curDataAll))\n",
    "  resultsMean.append(curResultMean)\n",
    "  resultsStd.append(curResultStd)\n",
    "\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(resultsMean)):\n",
    "  plt.errorbar(b_size, resultsMean[i], resultsStd[i], marker = 'o', alpha = 0.5)\n",
    "plt.grid()\n",
    "plt.title(\"Test Accuracy with Various Embedding Vector Lengths/Nodes in Multi-Layer Bidrectional LSTM\")\n",
    "plt.ylabel(\"Classification Accuracy (proportion) on Test Set\")\n",
    "plt.xlabel(\"Embedding Vector Length\")\n",
    "lgd = plt.legend(nodes, title=\"LSTM Nodes in Second Layer\", bbox_to_anchor=(1.04,0.5), loc=\"center left\")\n",
    "from google.colab import files\n",
    "plt.savefig(\"evls_nodes_multi_bi.png\",bbox_extra_artists=(lgd,), bbox_inches='tight', dpi = 1000)\n",
    "files.download(\"evls_nodes_multi_bi.png\")\n",
    "\n",
    "\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
